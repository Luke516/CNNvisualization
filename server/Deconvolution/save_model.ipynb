{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Visualization\n",
    "1. Activation maps\n",
    "2. Filter using gradient ascent\n",
    "3. Deep dream using gradient ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=\"\"\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tensorflow as tf \n",
    "import tensorflow.keras as keras\n",
    "# tf.config.gpu.set_per_process_memory_growth(True)\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a pretrained model like VGG16 and VGG19 trained on ImageNet to do the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = keras.applications.VGG19(include_top=False, input_shape=(224, 224, 3), weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg19.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version = 1\n",
    "# export_path = './model/{}'.format(version)\n",
    "# builder = tf.compat.v1.saved_model.builder.SavedModelBuilder(export_path)\n",
    "\n",
    "# ############### Build the map for signature_def ################\n",
    "# inputs = tf.compat.v1.saved_model.build_tensor_info(vgg19.input)\n",
    "\n",
    "# # map method name to tensor info\n",
    "# map_dict = []\n",
    "# for l in vgg19.layers[1:3]:\n",
    "#     l_ts = tf.cast(l.output, tf.int32)\n",
    "#     l_ts = l_ts[:, :, :, :4]\n",
    "#     map_dict.append((l.name, tf.compat.v1.saved_model.build_tensor_info(l_ts)))\n",
    "# map_dict = dict(map_dict)\n",
    "\n",
    "# # signature method name must be CLASSIFY_METHOD_NAME, PREDICT_METHOD_NAME or REGRESS_METHOD_NAME, \n",
    "# # they have different request format. please refer to https://www.tensorflow.org/tfx/serving/signature_defs \n",
    "# # and https://www.tensorflow.org/tfx/serving/api_rest/    \n",
    "# signature = (\n",
    "#     tf.compat.v1.saved_model.signature_def_utils.build_signature_def(\n",
    "#         inputs={'input': inputs},\n",
    "#         outputs=map_dict,\n",
    "#         method_name=tf.compat.v1.saved_model.signature_constants.PREDICT_METHOD_NAME \n",
    "#     )\n",
    "# )\n",
    "\n",
    "\n",
    "# # builder.add_meta_graph_and_variables(\n",
    "# #     tf.compat.v1.keras.backend.get_session(), [tf.compat.v1.saved_model.tag_constants.SERVING],\n",
    "# #     signature_def_map={'activation':signature,},\n",
    "# #     strip_default_attrs=True\n",
    "# # )\n",
    "# # builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconvnet_model(model, layer_name):\n",
    "    deconv_layers = []\n",
    "    for i in range(len(model.layers)):\n",
    "        if isinstance(model.layers[i], keras.layers.Conv2D):\n",
    "            weights = model.layers[i].get_weights()[0]\n",
    "            weights_h, weights_w, inp_filters, out_filters = weights.shape\n",
    "            deconv_layer = keras.layers.Conv2DTranspose(inp_filters, (weights_h, weights_w),\n",
    "                                                  input_shape=(model.layers[i].output_shape[1:]),\n",
    "                                                  strides=model.layers[i].get_config()['strides'],\n",
    "                                                  padding=model.layers[i].get_config()['padding'],\n",
    "                                                  activation=model.layers[i].get_config()['activation'],\n",
    "                                                  kernel_initializer=tf.constant_initializer(weights), \n",
    "                                                  bias_initializer=tf.zeros_initializer())\n",
    "            deconv_layers.append(deconv_layer)\n",
    "        elif isinstance(model.layers[i], keras.layers.MaxPooling2D):\n",
    "            deconv_layer = keras.layers.UpSampling2D(model.layers[i].get_config()['pool_size'], interpolation=\"bilinear\")\n",
    "            deconv_layers.append(deconv_layer)\n",
    "        \n",
    "        elif isinstance(model.layers[i], keras.layers.AveragePooling2D):\n",
    "            deconv_layer = keras.layers.UpSampling2D(model.layers[i].get_config()['pool_size'], interpolation=\"bilinear\")\n",
    "            deconv_layers.append(deconv_layer)\n",
    "            \n",
    "        if model.layers[i].name == layer_name:\n",
    "            break\n",
    "    deconv_model = tf.keras.Sequential(deconv_layers[::-1])\n",
    "    return deconv_model\n",
    "\n",
    "# visualize the filter activation using deconvolution model.\n",
    "def post_process(img):\n",
    "    img -= tf.reduce_min(img, axis=[1,2,3], keepdims=True)\n",
    "    img *= 1.0 / (tf.reduce_max(img, axis=[1,2,3], keepdims=True) + 1e-8)\n",
    "    img = tf.cast(img * 255, tf.int32)\n",
    "    return img\n",
    "\n",
    "def visualization_using_deconvolution(orig_model, deconv_model, vis_image, feature_to_visualize):\n",
    "    vis_image = tf.image.resize(vis_image, (224, 224))\n",
    "\n",
    "    vis_image = orig_model(vis_image)\n",
    "    feature_map = vis_image[:, :, :, feature_to_visualize:feature_to_visualize+1] # shape [batch_size, width, height, 1]\n",
    "    paddings = [[0,0],\n",
    "                [0,0],\n",
    "                [0,0],\n",
    "                [feature_to_visualize,vis_image.shape[-1]-feature_to_visualize-1]]\n",
    "    output = tf.pad(feature_map, paddings, 'CONSTANT')\n",
    "    deconv_output = deconv_model(output)\n",
    "    return deconv_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_layer = 'block4_conv1'\n",
    "target_output = vgg19.get_layer(vis_layer).output \n",
    "vgg19_submodel = tf.keras.Model(vgg19.input, target_output)\n",
    "vgg19_deconv = deconvnet_model(vgg19, vis_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_outputs = []\n",
    "img = tf.compat.v1.placeholder(dtype=tf.float32, shape=[1, 224, 224, 3])\n",
    "for idx in range(16):\n",
    "    vis_output = visualization_using_deconvolution(vgg19_submodel, vgg19_deconv, img, idx)\n",
    "    vis_outputs.append(post_process(vis_output))\n",
    "layer_outputs = tf.stack(vis_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'stack:0' shape=(16, 1, 224, 224, 3) dtype=int32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0827 17:28:31.245250 140215473108736 deprecation.py:323] From <ipython-input-9-e6af897fbb12>:6: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'./model/1/saved_model.pb'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version = 1\n",
    "export_path = './model/{}'.format(version)\n",
    "builder = tf.compat.v1.saved_model.builder.SavedModelBuilder(export_path)\n",
    "\n",
    "############### Build the map for signature_def ################\n",
    "inputs = tf.compat.v1.saved_model.build_tensor_info(img)\n",
    "\n",
    "# map method name to tensor info\n",
    "map_dict = []\n",
    "# img = tf.cast(img, tf.int32)\n",
    "map_dict.append((layer_outputs.name, tf.compat.v1.saved_model.build_tensor_info(layer_outputs)))\n",
    "map_dict = dict(map_dict)\n",
    "\n",
    "# signature method name must be CLASSIFY_METHOD_NAME, PREDICT_METHOD_NAME or REGRESS_METHOD_NAME, \n",
    "# they have different request format. please refer to https://www.tensorflow.org/tfx/serving/signature_defs \n",
    "# and https://www.tensorflow.org/tfx/serving/api_rest/    \n",
    "signature2 = (\n",
    "    tf.compat.v1.saved_model.signature_def_utils.build_signature_def(\n",
    "        inputs={'input': inputs},\n",
    "        outputs=map_dict,\n",
    "        method_name=tf.compat.v1.saved_model.signature_constants.PREDICT_METHOD_NAME \n",
    "    )\n",
    ")\n",
    "\n",
    "# I don't know why, but can't use same tag here, or their key mix?\n",
    "builder.add_meta_graph_and_variables(\n",
    "    tf.compat.v1.keras.backend.get_session(),\n",
    "    [tf.compat.v1.saved_model.tag_constants.SERVING],\n",
    "    signature_def_map={'deconv':signature2,},\n",
    "    strip_default_attrs=True\n",
    ")\n",
    "# builder.add_meta_graph(['deconv'],\n",
    "#     signature_def_map={'deconv':signature2,},\n",
    "#     strip_default_attrs=True\n",
    "# )\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stack:0': name: \"stack:0\"\n",
       " dtype: DT_INT32\n",
       " tensor_shape {\n",
       "   dim {\n",
       "     size: 16\n",
       "   }\n",
       "   dim {\n",
       "     size: 1\n",
       "   }\n",
       "   dim {\n",
       "     size: 224\n",
       "   }\n",
       "   dim {\n",
       "     size: 224\n",
       "   }\n",
       "   dim {\n",
       "     size: 3\n",
       "   }\n",
       " }}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/home/kjliu/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\r\n",
      "  File \"/home/kjliu/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\r\n",
      "  File \"/home/kjliu/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n",
      "  File \"/usr/lib/python3.5/imp.py\", line 242, in load_module\r\n",
      "    return load_dynamic(name, filename, file)\r\n",
      "  File \"/usr/lib/python3.5/imp.py\", line 342, in load_dynamic\r\n",
      "    return _load(spec)\r\n",
      "ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/kjliu/.local/bin/saved_model_cli\", line 7, in <module>\r\n",
      "    from tensorflow.python.tools.saved_model_cli import main\r\n",
      "  File \"/home/kjliu/.local/lib/python3.5/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n",
      "    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n",
      "  File \"/home/kjliu/.local/lib/python3.5/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n",
      "    from tensorflow.python import pywrap_tensorflow\r\n",
      "  File \"/home/kjliu/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 74, in <module>\r\n",
      "    raise ImportError(msg)\r\n",
      "ImportError: Traceback (most recent call last):\r\n",
      "  File \"/home/kjliu/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\r\n",
      "  File \"/home/kjliu/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\r\n",
      "  File \"/home/kjliu/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n",
      "  File \"/usr/lib/python3.5/imp.py\", line 242, in load_module\r\n",
      "    return load_dynamic(name, filename, file)\r\n",
      "  File \"/usr/lib/python3.5/imp.py\", line 342, in load_dynamic\r\n",
      "    return _load(spec)\r\n",
      "ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\r\n",
      "\r\n",
      "\r\n",
      "Failed to load the native TensorFlow runtime.\r\n",
      "\r\n",
      "See https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n",
      "\r\n",
      "for some common reasons and solutions.  Include the entire stack trace\r\n",
      "above this error message when asking for help.\r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir ./model/1 --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (tensorflow2.0)",
   "language": "python",
   "name": "tensorflow2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
